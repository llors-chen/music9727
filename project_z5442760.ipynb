{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M4LJ_S0d5g1"
      },
      "source": [
        "## project 9727 \n",
        "### Wenhao Chen \n",
        "### ZID:z5442760\n",
        "### part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OP_hPmjeTzMw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            user_id                      \"artistname\"  \\\n",
            "0  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
            "1  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
            "2  9cc0cfd4d7d7885102480dd99e7a90d6                      Tiffany Page   \n",
            "3  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
            "4  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
            "\n",
            "                                         \"trackname\"  \"playlistname\"  \n",
            "0               (The Angels Wanna Wear My) Red Shoes  HARD ROCK 2010  \n",
            "1  (What's So Funny 'Bout) Peace, Love And Unders...  HARD ROCK 2010  \n",
            "2                                   7 Years Too Late  HARD ROCK 2010  \n",
            "3                              Accidents Will Happen  HARD ROCK 2010  \n",
            "4                                             Alison  HARD ROCK 2010  \n",
            "  artist                   song                                        link  \\\n",
            "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
            "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
            "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
            "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
            "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
            "\n",
            "                                                text  \n",
            "0  Look at her face, it's a wonderful face  \\r\\nA...  \n",
            "1  Take it easy with me, please  \\r\\nTouch me gen...  \n",
            "2  I'll never know why I had to go  \\r\\nWhy I had...  \n",
            "3  Making somebody happy is a question of give an...  \n",
            "4  Making somebody happy is a question of give an...  \n"
          ]
        }
      ],
      "source": [
        "# Loading the Data\n",
        "import pandas as pd\n",
        "\n",
        "# 将 CSV 文件导入为 DataFrame\n",
        "spotify_df = pd.read_csv('spotify_dataset.csv',on_bad_lines='skip', quotechar='\"')\n",
        "song_df = pd.read_csv(\"spotify_millsongdata.csv\",on_bad_lines='skip', quotechar='\"')\n",
        "\n",
        "spotify_df = spotify_df.dropna()\n",
        "song_df = song_df.dropna()\n",
        "\n",
        "# 打印前几行数据以确认导入成功\n",
        "print(spotify_df.head())\n",
        "print(song_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QcaZbE-J3ID",
        "outputId": "a1e61f01-d853-4120-c803-b2eeef18d7ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 12856831 entries, 0 to 12891679\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Dtype \n",
            "---  ------        ----- \n",
            " 0   user_id       object\n",
            " 1   artistname    object\n",
            " 2   trackname     object\n",
            " 3   playlistname  object\n",
            "dtypes: object(4)\n",
            "memory usage: 490.4+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 57650 entries, 0 to 57649\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   artist  57650 non-null  object\n",
            " 1   song    57650 non-null  object\n",
            " 2   link    57650 non-null  object\n",
            " 3   text    57650 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 1.8+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "spotify_df.columns = spotify_df.columns.str.replace('\"', '').str.strip()\n",
        "\n",
        "print(spotify_df.info())\n",
        "print(song_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LIM1gSaQpg_",
        "outputId": "6b86d3e0-fc91-4110-f7b3-12258851d768"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\forsa\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\forsa\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\forsa\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            user_id                        artistname  \\\n",
            "0  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
            "1  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
            "2  9cc0cfd4d7d7885102480dd99e7a90d6                      Tiffany Page   \n",
            "3  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
            "4  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
            "\n",
            "                                           trackname    playlistname  \n",
            "0               (The Angels Wanna Wear My) Red Shoes  hard rock 2010  \n",
            "1  (What's So Funny 'Bout) Peace, Love And Unders...  hard rock 2010  \n",
            "2                                   7 Years Too Late  hard rock 2010  \n",
            "3                              Accidents Will Happen  hard rock 2010  \n",
            "4                                             Alison  hard rock 2010  \n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Define preprocessing function\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    if not isinstance(text, str):\n",
        "        return str(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s()-]', '', text)   #######################\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens] ####################\n",
        "    return ' '.join(tokens) \n",
        "\n",
        "spotify_df['playlistname'] = spotify_df['playlistname'].apply(preprocess_text)\n",
        "# spotify_df = spotify_df.applymap(preprocess_text)\n",
        "# song_df = spotify_df.applymap(preprocess_text)\n",
        "\n",
        "print(spotify_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kzFA4CcYKaJ3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "随机提取的10个不重复歌单 作为随机推荐:\n",
            "                                  playlistname\n",
            "7773955                                 u loud\n",
            "131568                            mount kimble\n",
            "10668163             sun kil moon - among leaf\n",
            "944673                                nocturne\n",
            "944469                                 chicago\n",
            "944496                             de beauvoir\n",
            "10667114  lazify - james brown - funky drummer\n",
            "10667139        lazify - killing joke - eighty\n",
            "132823                                trip-hop\n",
            "683831                               barricada\n",
            "\n",
            "基于关键词 'love' 的推荐歌单:\n",
            "1. enrique iglesias sex love ( deluxe )\n",
            "2. gave love\n",
            "3. john legend - love future\n",
            "4. john newman - love\n",
            "5. yelawolf love story\n",
            "6. love jaïpur\n",
            "7. love ( feat josh jakq )\n",
            "8. last chance love\n",
            "9. lastfm loved track\n",
            "10. derek domino layla assorted love song\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# 获取随机10个用户的歌单列表\n",
        "random_users = random.sample(list(spotify_df['user_id'].unique()), 10)\n",
        "user_playlists = spotify_df[spotify_df['user_id'].isin(random_users)]\n",
        "\n",
        "# 从用户歌单中随机提取10个不重复的歌单\n",
        "unique_playlists = user_playlists[['playlistname']].drop_duplicates()\n",
        "random_playlists = unique_playlists.sample(n=10, replace=False)\n",
        "print(\"\\n随机提取的10个不重复歌单 作为随机推荐:\")\n",
        "print(random_playlists)\n",
        "\n",
        "# 基于关键词进行推荐\n",
        "def recommend_playlists(keyword, df, top_n=10):\n",
        "    keyword = preprocess_text(keyword)\n",
        "    df['keyword_match'] = df['playlistname'].apply(lambda x: keyword in x)\n",
        "    recommendations = df[df['keyword_match']].drop_duplicates(subset=['playlistname']).head(top_n)\n",
        "    return recommendations['playlistname'].tolist()\n",
        "\n",
        "# 示例关键词\n",
        "keyword = \"love\"\n",
        "\n",
        "# 推荐10条相关的 playlistname\n",
        "recommendations = recommend_playlists(keyword, spotify_df)\n",
        "\n",
        "print(\"\\n基于关键词 '{}' 的推荐歌单:\".format(keyword))\n",
        "for i, playlist in enumerate(recommendations, 1):\n",
        "    print(\"{}. {}\".format(i, playlist))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "每个歌单的关键词:\n",
            "u loud: for, girl, in, it, little, love, night, one, the, you\n",
            "mount kimble: feat, king, krule, many, so, stray, sullen, that, time, times\n",
            "sun kil moon - among leaf: attractive, blues, not, talented, that, the, uk, was, yet, young\n",
            "nocturne: 39, act, flat, in, la, no, nocturne, of, op, parsifal\n",
            "chicago: and, east, me, news, of, on, part, step, the, world\n",
            "de beauvoir: all, blah, not, now, of, oh, own, pedestrian, prisstina, pt\n",
            "lazify - james brown - funky drummer: do, funky, it, me, single, stuff, the, to, version, you\n",
            "lazify - killing joke - eighty: 2007, digital, love, me, my, new, no, remaster, the, to\n",
            "trip-hop: does, like, look, part, soul, stem, the, what, you, your\n",
            "barricada: azulejo, bienvenidos, blanco, en, frío, hay, negra, negro, no, oveja\n",
            "\n",
            "基于关键词 'love' 的推荐歌单:\n",
            "1. u loud\n",
            "2. lazify - killing joke - eighty\n",
            "3. sun kil moon - among leaf\n",
            "4. lazify - james brown - funky drummer\n",
            "5. trip-hop\n",
            "6. mount kimble\n",
            "7. nocturne\n",
            "8. chicago\n",
            "9. de beauvoir\n",
            "10. barricada\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def extract_keywords(text):\n",
        "    vectorizer = CountVectorizer(max_features=10)\n",
        "    X = vectorizer.fit_transform([text])\n",
        "    return vectorizer.get_feature_names_out()\n",
        "\n",
        "# 为每个歌单获取10个关键词\n",
        "playlist_keywords = {}\n",
        "playlist_tracknames = {}\n",
        "for playlist in random_playlists['playlistname']:\n",
        "    tracknames = ' '.join(user_playlists[user_playlists['playlistname'] == playlist]['trackname'].tolist())\n",
        "    keywords = extract_keywords(tracknames)\n",
        "    playlist_keywords[playlist] = keywords\n",
        "    playlist_tracknames[playlist] = tracknames\n",
        "\n",
        "print(\"\\n每个歌单的关键词:\")\n",
        "for playlist, keywords in playlist_keywords.items():\n",
        "    print(f\"{playlist}: {', '.join(keywords)}\")\n",
        "\n",
        "# 准备数据用于训练贝叶斯分类器\n",
        "data = []\n",
        "labels = []\n",
        "for playlist, keywords in playlist_keywords.items():\n",
        "    for keyword in keywords:\n",
        "        data.append(keyword)\n",
        "        labels.append(playlist)\n",
        "\n",
        "# 使用 CountVectorizer 将关键词转换为特征向量\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(data)\n",
        "y = labels\n",
        "\n",
        "# 使用 Multinomial Naive Bayes 训练模型\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X, y)\n",
        "\n",
        "# 基于输入关键词推荐新的歌单\n",
        "def recommend_playlist_based_on_keyword(keyword, model, vectorizer, tracknames_dict, top_n=10):\n",
        "    keyword_processed = preprocess_text(keyword)\n",
        "    X_new = vectorizer.transform([keyword_processed])\n",
        "    predicted_playlist = model.predict(X_new)[0]\n",
        "\n",
        "    # 计算相似度\n",
        "    input_vector = vectorizer.transform([keyword_processed])\n",
        "    similarities = []\n",
        "    for playlist, tracknames in tracknames_dict.items():\n",
        "        playlist_vector = vectorizer.transform([tracknames])\n",
        "        similarity = cosine_similarity(input_vector, playlist_vector)\n",
        "        similarities.append((playlist, similarity[0][0]))\n",
        "\n",
        "    # 根据相似度排序并推荐\n",
        "    sorted_playlists = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "    recommended_playlists = [playlist for playlist, _ in sorted_playlists[:top_n]]\n",
        "    return recommended_playlists\n",
        "\n",
        "# 示例关键词\n",
        "input_keyword = \"love\"\n",
        "\n",
        "# 推荐基于输入关键词的新歌单\n",
        "recommended_playlists = recommend_playlist_based_on_keyword(input_keyword, mnb, vectorizer, playlist_tracknames)\n",
        "print(f\"\\n基于关键词 '{input_keyword}' 的推荐歌单:\")\n",
        "for i, playlist in enumerate(recommended_playlists, 1):\n",
        "    print(f\"{i}. {playlist}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  artist                   song                                        link  \\\n",
            "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
            "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
            "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
            "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
            "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
            "\n",
            "                                                text  \n",
            "0  Look at her face, it's a wonderful face  \\r\\nA...  \n",
            "1  Take it easy with me, please  \\r\\nTouch me gen...  \n",
            "2  I'll never know why I had to go  \\r\\nWhy I had...  \n",
            "3  Making somebody happy is a question of give an...  \n",
            "4  Making somebody happy is a question of give an...  \n"
          ]
        }
      ],
      "source": [
        "print(song_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "每个歌单的关键词:\n",
            "                           playlistname  \\\n",
            "0                               chicago   \n",
            "1                           de beauvoir   \n",
            "2  lazify - james brown - funky drummer   \n",
            "3        lazify - killing joke - eighty   \n",
            "4                          mount kimble   \n",
            "5             sun kil moon - among leaf   \n",
            "6                              trip-hop   \n",
            "7                                u loud   \n",
            "\n",
            "                                            keywords  \n",
            "0          tell wan run na want body oh yo oooh make  \n",
            "1  blah yeah voice life need bring faithfully lov...  \n",
            "2  jane mary river water washing know drop im dip...  \n",
            "3  dance war desire come want reptile tick floor ...  \n",
            "4       ra slow rida tari fall skip ta body beat let  \n",
            "5  young billy love strong said girl nail board h...  \n",
            "6     dont numb wan valentine let na ra love feel im  \n",
            "7   fever got heaven dont oh thing know im burn kiss  \n",
            "\n",
            "基于歌单关键词推荐的20首歌:\n",
            "48523. Slow\n",
            "54699. Tell Me\n",
            "8785. Float N' Slow - My Gift To You Bad Boy (Remix)\n",
            "31657. Physical\n",
            "49202. Come To Me\n",
            "53438. Take Me To The River\n",
            "24549. Who Do You Love?\n",
            "13643. Lazy Love\n",
            "11801. Curious\n",
            "45193. Put That Thang On U\n",
            "50705. I Want To Know What Love Is\n",
            "19362. Tina's Wish\n",
            "32612. Don't Wanna Dance Alone\n",
            "52540. Johnny Too Bad Freestyle\n",
            "38070. Love Me Now\n",
            "39291. I Just Wanna Love U (Offcial Kanye West Mumtribute Mix)\n",
            "55340. Jenny\n",
            "29401. Who Do You Love\n",
            "48170. Oh Bumbo Klaat\n",
            "55594. Who Slayed Baby Jane?\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "song_df['text'] = song_df['text'].apply(preprocess_text)\n",
        "\n",
        "# 提取随机歌单中的歌曲，并创建一个独立的df用于合并trackname和song\n",
        "random_playlist_songs = user_playlists[user_playlists['playlistname'].isin(random_playlists['playlistname'])]\n",
        "track_song_df = pd.merge(random_playlist_songs, song_df, left_on='trackname', right_on='song', how='inner')\n",
        "\n",
        "# 提取每首歌曲的TF-IDF特征\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(track_song_df['text'])\n",
        "\n",
        "# 提取每个歌单的所有歌词并合并为一个文本\n",
        "playlist_lyrics = track_song_df.groupby('playlistname')['text'].apply(' '.join).reset_index()\n",
        "\n",
        "# 提取关键词\n",
        "def extract_keywords(text, vectorizer, top_n=10):\n",
        "    X = vectorizer.transform([text])\n",
        "    indices = X.toarray().argsort()[0, -top_n:][::-1]\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    keywords = [feature_names[i] for i in indices]\n",
        "    return ' '.join(keywords)\n",
        "\n",
        "# 提取每个歌单的关键词\n",
        "playlist_lyrics['keywords'] = playlist_lyrics['text'].apply(lambda x: extract_keywords(x, tfidf_vectorizer))\n",
        "\n",
        "print(\"\\n每个歌单的关键词:\")\n",
        "print(playlist_lyrics[['playlistname', 'keywords']])\n",
        "\n",
        "# 合并所有歌单的关键词\n",
        "all_keywords = ' '.join(playlist_lyrics['keywords'].tolist())\n",
        "\n",
        "# 使用合并的关键词搜索歌曲\n",
        "def recommend_songs_based_on_keywords(keywords, song_df, vectorizer, top_n=20):\n",
        "    keywords_vector = vectorizer.transform([keywords])\n",
        "    song_vectors = vectorizer.transform(song_df['text'])\n",
        "    similarities = cosine_similarity(keywords_vector, song_vectors).flatten()\n",
        "    top_indices = similarities.argsort()[-top_n*2:][::-1]  # 获取多一些，以防去重后不足20首\n",
        "    recommended_songs = song_df.iloc[top_indices]\n",
        "    recommended_songs = recommended_songs.drop_duplicates(subset='song').head(top_n)\n",
        "    return recommended_songs\n",
        "\n",
        "# 推荐20首基于合并关键词的歌曲\n",
        "recommended_songs = recommend_songs_based_on_keywords(all_keywords, song_df, tfidf_vectorizer)\n",
        "print(f\"\\n基于歌单关键词推荐的20首歌:\")\n",
        "for i, row in recommended_songs.iterrows():\n",
        "    print(f\"{i+1}. {row['song']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
